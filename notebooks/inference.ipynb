{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiyuanChen726/BreastAgeNet/blob/main/inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SiyuanChen726/BreastAgeNet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4MRcZ59sls7",
        "outputId": "d4f02e9f-4f80-4f11-8a70-a25e5402fb3f"
      },
      "id": "M4MRcZ59sls7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BreastAgeNet'...\n",
            "remote: Enumerating objects: 295, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 295 (delta 65), reused 8 (delta 7), pack-reused 165 (from 1)\u001b[K\n",
            "Receiving objects: 100% (295/295), 24.67 MiB | 16.02 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y openslide-tools libopenslide0\n",
        "!pip install openslide-python"
      ],
      "metadata": {
        "id": "tM9yyI98smzD"
      },
      "id": "tM9yyI98smzD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the files with corrected Google Drive links\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1tDfFXZvB6PASPW-4OMrBU-HQo7optH53' -O 'BreastAgeNet_bestModel.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4985WhHtfK3",
        "outputId": "9a45066a-5306-42e4-d37a-941cec6161cd"
      },
      "id": "u4985WhHtfK3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-30 06:15:45--  https://drive.google.com/uc?export=download&id=1tDfFXZvB6PASPW-4OMrBU-HQo7optH53\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.68.139, 74.125.68.138, 74.125.68.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.68.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1tDfFXZvB6PASPW-4OMrBU-HQo7optH53&export=download [following]\n",
            "--2024-11-30 06:15:45--  https://drive.usercontent.google.com/download?id=1tDfFXZvB6PASPW-4OMrBU-HQo7optH53&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.175.132, 2404:6800:4003:c1c::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.175.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9995011 (9.5M) [application/octet-stream]\n",
            "Saving to: ‘BreastAgeNet_bestModel.pt’\n",
            "\n",
            "BreastAgeNet_bestMo 100%[===================>]   9.53M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-11-30 06:15:48 (76.2 MB/s) - ‘BreastAgeNet_bestModel.pt’ saved [9995011/9995011]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append('/content/BreastAgeNet')\n",
        "\n",
        "import openslide\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from utils_vis import *\n",
        "from utils_train import *"
      ],
      "metadata": {
        "id": "IutDsBDgssTk"
      },
      "id": "IutDsBDgssTk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ec14c55-7219-4921-a29c-83d2fc962ac9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ec14c55-7219-4921-a29c-83d2fc962ac9",
        "outputId": "cc07be53-b8d3-48aa-963b-45f6ed3f86b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-aa43e33e99df>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(ckpt_name))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "ckpt_name = \"BreastAgeNet_bestModel.pt\"\n",
        "n_feats = get_dim_input(model_name = \"UNI\")\n",
        "\n",
        "model = BreastAgeNet(n_feats, attention=\"MultiHeadAttention\", n_classes=3, n_heads=8, n_latent=512, embed_attn=True)\n",
        "model.load_state_dict(torch.load(ckpt_name))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clinic_df = pd.read_csv(\"/scratch/prj/cb_normalbreast/Siyuan/prj_normal/BreastAgeNet/DATA/clinicData/AllCohorts.csv\")\n",
        "clinic_df = clinic_df.loc[clinic_df[\"cohort\"]==\"development\", :].copy()\n",
        "\n",
        "valid_patches = []\n",
        "for fea_pt in clinic_df.h5df.values:\n",
        "    with h5py.File(fea_pt, \"r\") as file:\n",
        "        bag = np.array(file[\"embeddings\"])\n",
        "        bag = np.squeeze(bag)\n",
        "        img_id = np.array(file[\"patch_id\"])\n",
        "    img_id = [i.decode(\"utf-8\") for i in img_id]\n",
        "    bag_df = pd.DataFrame(bag)\n",
        "    bag_df.index = img_id\n",
        "\n",
        "    csv_pt =  os.path.join(Path(fea_pt).parent, Path(fea_pt).stem.split('_bagFeature_')[0]+'_patch.csv')\n",
        "    df = pd.read_csv(csv_pt)\n",
        "    valid_id = list(df['patch_id'][df['TC_epi'] > 0.9])\n",
        "    valid_id = list(set(valid_id) & set(bag_df.index))\n",
        "    valid_patches.extend(valid_id)\n",
        "print(len(valid_patches))\n",
        "\n",
        "valid_wsis = [\"_\".join(i.split(\"_\")[:3]) for i in valid_patches]\n",
        "print(len(np.unique(valid_wsis)))\n",
        "\n",
        "a, b = np.unique(valid_wsis, return_counts=True)\n",
        "filtered_a = [i for i, count in zip(a, b) if count >= 5]\n",
        "print(len(filtered_a))\n",
        "print(len(np.unique([i.split(\"_\")[0] for i in filtered_a])))\n",
        "clinic_df = clinic_df[clinic_df[\"wsi_id\"].isin(filtered_a)]\n",
        "print(\"Filtered DataFrame length:\", len(clinic_df))\n",
        "print(\"Unique age groups and counts:\", np.unique(clinic_df[\"age_group\"], return_counts=True))\n",
        "\n",
        "\n",
        "print(len(valid_patches))\n",
        "valid_patches = [i for i in valid_patches if \"_\".join(i.split(\"_\")[:3]) in filtered_a]\n",
        "print(len(valid_patches))"
      ],
      "metadata": {
        "id": "wnBbGeVHugCx"
      },
      "id": "wnBbGeVHugCx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f48b96",
      "metadata": {
        "id": "11f48b96"
      },
      "outputs": [],
      "source": [
        "df = clinic_df.copy() # file containing all {wsi_id}_UNI.h5 files for the dataset\n",
        "df['h5df'] = [Path(i) for i in df[\"h5df\"]]\n",
        "\n",
        "valid_patches = valid_patches # select patches with TC_epi > 0.9\n",
        "test_dblock = DataBlock(blocks = (TransformBlock, CategoryBlock),\n",
        "               get_x = ColReader('h5df'),\n",
        "               get_y = ColReader('age_group'),\n",
        "               item_tfms = MILBagTransform(df.h5df, bag_size, valid_patches))\n",
        "\n",
        "test_dls = test_dblock.dataloaders(df, bs=bag_size, shuffle=False)\n",
        "dataloaders = test_dls.test_dl(df, with_labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd56b22d-48ed-4603-aaaf-081d9bcad63d",
      "metadata": {
        "scrolled": true,
        "id": "fd56b22d-48ed-4603-aaaf-081d9bcad63d"
      },
      "outputs": [],
      "source": [
        "# Initialize test loader, assume clinic_df is pre-defined\n",
        "phase = 'test'\n",
        "model.eval()\n",
        "\n",
        "predicted_ranks = []\n",
        "truelabels = []\n",
        "df = pd.DataFrame()  # Initialize empty DataFrame\n",
        "\n",
        "# Loop through the test data\n",
        "for repeat in range(10):\n",
        "    for (patch_ids, inputs), labels in tqdm(dataloaders):  # Ensure 'dataloaders' is correctly defined elsewhere\n",
        "        patch_ids = np.array(patch_ids)  # Shape: (150, 7)\n",
        "        patch_ids = np.transpose(patch_ids)  # Shape: (7, 150)\n",
        "        patch_ids = patch_ids.flatten()  # Flattened to shape (1050,)\n",
        "\n",
        "        # Enable gradients only if in training phase\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "            logits, embeddings, attentions = model(inputs)\n",
        "\n",
        "            attentions = attentions.view(-1, attentions.shape[-1])  # Flatten attentions\n",
        "            embeddings = embeddings.view(-1, embeddings.shape[-1])  # Flatten embeddings\n",
        "            probs = torch.sigmoid(logits)  # Shape: [batch_size, n_classes]\n",
        "            binary_predictions = (probs > 0.5).int()  # Shape: [batch_size, n_classes]\n",
        "            ranks = binary_predictions.sum(dim=1)  # Sum the predictions to get a rank score\n",
        "            predicted_ranks += ranks.tolist()  # Accumulate predicted ranks\n",
        "            truelabels += labels.tolist()  # Accumulate true labels\n",
        "\n",
        "        # Concatenate patch_ids, embeddings, and attentions\n",
        "        # Assuming patch_ids, embeddings, and attentions are of compatible shapes\n",
        "        combined_data = np.column_stack((repeat, patch_ids, embeddings.cpu().numpy(), attentions.cpu().numpy()))  # Convert to numpy\n",
        "        dfi = pd.DataFrame(combined_data, columns=['repeat'] + ['patch_id'] +\n",
        "                                                    [f'embedding_{i}' for i in range(embeddings.shape[1])] +\n",
        "                                                    [f'attention_{i}' for i in range(attentions.shape[1])])\n",
        "\n",
        "        # Append new data to the main DataFrame\n",
        "        df = pd.concat([df, dfi], axis=0, ignore_index=True)\n",
        "\n",
        "# Remove duplicates from the final DataFrame\n",
        "df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3010228c-1629-437c-adfa-eaea44516533",
      "metadata": {
        "id": "3010228c-1629-437c-adfa-eaea44516533"
      },
      "outputs": [],
      "source": [
        "MAE = np.abs(truelabels - np.array(predicted_ranks)).mean()\n",
        "print(f'Mean Absolute Error (MAE): {MAE}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# average for each WSI"
      ],
      "metadata": {
        "id": "oNmR-FB8wLvl"
      },
      "id": "oNmR-FB8wLvl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vote for each patient\n",
        "\n",
        "from scipy.special import expit  # For sigmoid function\n",
        "\n",
        "# Step 1: Convert 'branch_0', 'branch_1', 'branch_2' to numeric (if necessary)\n",
        "outputs_WSI['branch_0'] = pd.to_numeric(outputs_WSI['branch_0'], errors='coerce')\n",
        "outputs_WSI['branch_1'] = pd.to_numeric(outputs_WSI['branch_1'], errors='coerce')\n",
        "outputs_WSI['branch_2'] = pd.to_numeric(outputs_WSI['branch_2'], errors='coerce')\n",
        "\n",
        "# Step 2: Group by 'wsi_id' and calculate the mean for each branch across repeats\n",
        "averaged_data = outputs_WSI.groupby('wsi_id')[['branch_0', 'branch_1', 'branch_2']].mean().reset_index()\n",
        "\n",
        "# Step 3: Apply sigmoid to the averaged values\n",
        "averaged_data['sigmoid_0'] = expit(averaged_data['branch_0'])  # Sigmoid for branch 0\n",
        "averaged_data['sigmoid_1'] = expit(averaged_data['branch_1'])  # Sigmoid for branch 1\n",
        "averaged_data['sigmoid_2'] = expit(averaged_data['branch_2'])  # Sigmoid for branch 2\n",
        "\n",
        "# Step 4: Convert sigmoid values to binary (0 or 1)\n",
        "averaged_data['binary_0'] = (averaged_data['sigmoid_0'] >= 0.5).astype(int)\n",
        "averaged_data['binary_1'] = (averaged_data['sigmoid_1'] >= 0.5).astype(int)\n",
        "averaged_data['binary_2'] = (averaged_data['sigmoid_2'] >= 0.5).astype(int)\n",
        "\n",
        "# Step 5: Sum the binary predictions to get the final prediction\n",
        "averaged_data['final_prediction'] = averaged_data[['binary_0', 'binary_1', 'binary_2']].sum(axis=1)\n",
        "\n",
        "# Display the results (only final prediction for simplicity)\n",
        "print(averaged_data[['wsi_id', 'final_prediction']])\n",
        "\n"
      ],
      "metadata": {
        "id": "Aj0UUtpywJ81"
      },
      "id": "Aj0UUtpywJ81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2913bf8c-8855-480c-92a7-4752b8acdf6e",
      "metadata": {
        "id": "2913bf8c-8855-480c-92a7-4752b8acdf6e"
      },
      "outputs": [],
      "source": [
        "df[\"wsi_id\"] = [i.split(\"_\")[0] for i in list(df[\"patch_id\"])]\n",
        "df = pd.merge(df, clinic_df, on=\"wsi_id\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
